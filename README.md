## 鸢尾花数据集的KNN分类

Number of questions: 1 Total score: 100

Time:09-30 12:12to10-15 12:13
一. 简答题（1 questions，100 points in total）

1. (简答题)

小组作业是实现鸢尾花数据集的KNN分类

计算机专业课程小组作业要求：鸢尾花数据集 KNN 分类实现
一、作业背景与目的

鸢尾花（Iris）数据集是机器学习领域经典的分类任务数据集，包含 3 种不同品种的鸢尾花（山鸢尾、变色鸢尾、维吉尼亚鸢尾），每种品种各 50 个样本，每个样本包含 4 个特征（花萼长度、花萼宽度、花瓣长度、花瓣宽度）及 1 个类别标签。

本次小组作业以 “KNN（K 近邻）分类算法” 为核心，要求小组通过编程实现算法、处理数据集、完成分类任务并进行结果分析，旨在达成以下目的：

    深入理解 KNN 算法的核心原理（如距离度量、K 值选择、投票机制），掌握从算法理论到代码实现的完整流程；

    熟练运用 Python 数据处理库（NumPy、Pandas）与可视化库（Matplotlib、Seaborn），完成数据加载、探索性分析与结果可视化；

    掌握机器学习任务的基本流程（数据预处理、模型构建、模型评估、超参数调优），建立 “问题分析 - 方案设计 - 实现验证 - 优化迭代” 的工程思维；

    培养小组协作能力，明确分工、高效沟通，共同解决开发过程中的技术问题。

二、小组组成与分工要求
1. 小组规模

每组 3-4 人，鼓励跨学号、跨学习层次组队，确保成员能力互补（如擅长算法原理、擅长编程实现、擅长数据分析与可视化的成员搭配）。
2. 核心分工（需提交分工说明文档）

每组需明确成员职责，建议分工如下（可根据小组实际情况调整，需在文档中说明）：

    数据工程师：负责数据集加载（从 sklearn 库或本地文件读取）、数据预处理（缺失值检查与处理、特征标准化 / 归一化、数据集划分）；

    算法工程师：负责 KNN 算法核心逻辑实现（含距离度量函数、K 值选择逻辑、投票分类逻辑），禁止直接调用 sklearn 的KNeighborsClassifier，需手动实现基础版 KNN；

    可视化工程师：负责数据探索性可视化（特征分布直方图、特征间相关性热力图、样本散点图）、模型结果可视化（分类边界图、K 值对准确率影响曲线）；

    评估与优化工程师：负责模型评估指标计算（准确率、精确率、召回率、F1 分数、混淆矩阵）、K 值超参数调优（如网格搜索法）、结果分析与优化建议撰写。

三、作业核心任务与技术要求
任务 1：数据集处理（占比 20%）

    数据加载：通过 Python 加载鸢尾花数据集，可使用sklearn.datasets.load_iris()直接获取，或从 UCI 机器学习库（https://archive.ics.uci.edu/ml/datasets/Iris）下载 CSV 文件读取；

    数据探索：输出数据集基本信息（样本数量、特征维度、类别数量、各特征的均值 / 标准差 / 最小值 / 最大值），检查是否存在缺失值或异常值；

    数据预处理：

        特征标准化：由于 KNN 算法对特征尺度敏感（如 “花瓣长度” 单位为 cm，“花萼宽度” 单位为 mm，尺度差异会影响距离计算），需使用StandardScaler或手动实现 “均值减、标准差除” 的标准化操作；

        数据集划分：将数据集按 7:3 的比例划分为训练集（用于模型 “学习” 样本规律）和测试集（用于验证模型泛化能力），需使用随机种子（如random_state=42）保证划分结果可复现。

任务 2：KNN 算法手动实现（占比 30%）

需基于 Python（推荐使用 NumPy 实现向量运算，提升效率）手动实现 KNN 分类器，核心功能包括：

    距离度量函数：至少实现两种距离计算方式（欧氏距离、曼哈顿距离），允许用户在初始化模型时选择距离类型；

        欧氏距离公式：\(d(x,y)=\sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}\)（适用于连续型特征，假设特征独立）；

        曼哈顿距离公式：\(d(x,y)=\sum_{i=1}^{n}|x_i - y_i|\)（适用于特征存在异常值的场景，对离群点更鲁棒）；

    K 值选择与邻居筛选：对于测试集中的每个样本，计算其与训练集所有样本的距离，按距离从小到大排序后，筛选出前 K 个样本（即 “近邻”）；

    投票分类逻辑：统计 K 个近邻的类别标签，选择出现次数最多的类别作为当前测试样本的预测标签（若出现票数相同，可选择距离最近的样本类别作为最终结果）；

    模型类封装：将上述逻辑封装为MyKNN类，包含__init__(k, distance_type)（初始化 K 值和距离类型）、fit(X_train, y_train)（接收训练集数据，无需 “训练” 过程，仅存储训练集）、predict(X_test)（对测试集样本进行预测）三个核心方法。

任务 3：模型评估与超参数调优（占比 25%）

    评估指标计算：基于测试集的预测结果与真实标签，计算以下评估指标（需手动实现或使用sklearn.metrics库）：

        准确率（Accuracy）：正确分类的样本数占总样本数的比例，适用于类别分布均衡的场景；

        精确率（Precision）、召回率（Recall）、F1 分数：针对每一类（如山鸢尾）计算，解决 “类别不均衡” 场景下准确率的局限性（如某类样本占比 90%，模型全预测为该类也能得 90% 准确率，但对其他类预测无效）；

        混淆矩阵（Confusion Matrix）：直观展示模型在每一类上的分类错误情况（如 “将变色鸢尾误分为维吉尼亚鸢尾” 的样本数）；

    K 值调优：

        测试 K 取 1、3、5、7、9、11、13、15 时的模型准确率，绘制 “K 值 - 准确率” 折线图；

        分析 K 值对模型性能的影响（如 K=1 时模型易过拟合，对噪声敏感；K 过大时模型欠拟合，无法捕捉样本细节），并确定最优 K 值（需说明选择依据，如 “K=5 时测试集准确率最高，且 K 继续增大后准确率无明显提升”）。

任务 4：结果可视化与分析（占比 15%）

    数据探索可视化：

        绘制 4 个特征的分布直方图（按类别着色），观察不同品种鸢尾花的特征分布差异（如 “维吉尼亚鸢尾的花瓣长度普遍大于山鸢尾”）；

        绘制特征间的相关性热力图，分析特征间的线性关系（如 “花瓣长度与花瓣宽度呈正相关”）；

        选择两个重要特征（如花瓣长度、花瓣宽度）绘制散点图（按类别着色），直观展示样本的类别聚集情况；

    模型结果可视化：

        基于最优 K 值，绘制测试集的混淆矩阵热力图，标注每一格的样本数量；

        选择两个特征，绘制 KNN 模型的分类边界图（可通过生成密集网格点，预测每个网格点的类别，再按类别着色实现），直观展示模型的分类能力。

四、提交要求与截止时间
1. 提交材料（需打包为 “小组名 - 鸢尾花 KNN 作业” 的压缩包，上传至课程平台）
    代码文件：命名为iris_knn.py，包含完整可运行代码（需添加详细注释，说明关键步骤的逻辑，如 “距离计算函数”“投票逻辑”），代码需满足 “运行即出结果”（无需用户手动修改路径或参数）；

    分工说明文档：命名为小组分工.md，说明小组成员姓名、学号、负责任务、具体贡献（如 “张三负责数据预处理，实现了特征标准化函数，并完成了数据集 7:3 划分”）；

    结果报告：命名为鸢尾花KNN分类报告.pdf，结构需包含 “1. 作业背景与目的”“2. 数据集分析”“3. KNN 算法实现细节”“4. 模型评估结果”“5. 超参数调优分析”“6. 问题与优化建议”“7. 小组总结”，报告需图文结合（插入可视化图表、关键代码片段），字数不少于 2000 字；

    运行结果录屏（可选加分）：若代码运行存在环境依赖问题，可提交 1-3 分钟录屏，展示代码运行过程及关键结果（如准确率输出、图表生成）。

2. 截止时间

2025年10_月15日 23:59（逾期提交按课程评分规则扣分，逾期 1 天扣 10 分，逾期 3 天以上按 0 分处理）。
五、评分标准

评分维度
分值
评分细则
数据处理（任务 1）
20
数据加载正确（5 分）、数据探索全面（5 分）、特征标准化合理（5 分）、数据集划分规范（5 分）
算法实现（任务 2）
30
距离度量函数正确（10 分）、K 近邻筛选逻辑无误（10 分）、投票分类结果准确（5 分）、代码封装规范（5 分）
模型评估与调优（任务 3）
25
评估指标计算完整（10 分）、K 值调优实验设计合理（8 分）、调优结果分析到位（7 分）
可视化与报告（任务 4）
15
可视化图表清晰且有分析（8 分）、报告结构完整（4 分）、内容逻辑严谨（3 分）
代码规范与协作
10
代码注释详细（4 分）、代码可运行无报错（3 分）、分工明确且贡献合理（3 分）
创新与加分
额外 10 分

1. 实现加权 KNN（按距离远近给近邻分配不同权重，如距离越近权重越大）；2. 对比不同距离度量（如欧氏距离 vs 曼哈顿距离）的效果差异；3. 提交运行录屏或额外优化建议
六、注意事项

    代码原创性：禁止直接抄袭网络代码（如 GitHub、CSDN 上的 KNN 实现），若发现代码高度雷同，小组所有成员均按 0 分处理；允许参考算法逻辑，但需用自己的代码实现，且在报告中注明参考来源；

    环境依赖：代码需明确标注依赖库版本（如numpy==1.24.3、pandas==2.0.1、matplotlib==3.7.1），建议使用 Anaconda 创建独立环境，避免因版本兼容问题导致代码无法运行；

    问题反馈：若开发过程中遇到技术问题（如算法逻辑卡壳、代码报错），可在课程讨论群提问，或预约 office hour 与教师沟通；

    协作要求：小组需定期召开线上 / 线下会议，记录协作过程（如会议纪要），避免 “一人全包” 或 “有人划水” 的情况，分工说明文档需真实反映成员贡献。

通过本次作业，希望同学们不仅能掌握 KNN 算法的实现，更能建立 “数据驱动决策” 的思维，为后续更复杂的机器学习算法学习打下基础！
